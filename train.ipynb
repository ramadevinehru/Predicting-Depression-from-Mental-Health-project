{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b77683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (112560, 17)\n",
      "Validation set: (28140, 17)\n",
      "Training target distribution:\n",
      " Depression\n",
      "0    92106\n",
      "1    20454\n",
      "Name: count, dtype: int64\n",
      "Validation target distribution:\n",
      " Depression\n",
      "0    23027\n",
      "1     5113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Drop columns not useful for prediction\n",
    "df_clean = df.drop(columns=[\"id\", \"Name\"])\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_cols.remove('Depression')  # Target column\n",
    "\n",
    "# Fill missing values\n",
    "df_clean[categorical_cols] = df_clean[categorical_cols].fillna('Unknown')\n",
    "df_clean[numerical_cols] = df_clean[numerical_cols].fillna(df_clean[numerical_cols].median())\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_clean[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
    "\n",
    "# Split into features and target\n",
    "X = df_clean.drop(columns='Depression')\n",
    "y = df_clean['Depression']\n",
    "\n",
    "# Train-validation split (80-20), stratified to preserve class distribution\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Final shapes\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n",
    "print(\"Training target distribution:\\n\", y_train.value_counts())\n",
    "print(\"Validation target distribution:\\n\", y_val.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d45b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (112560, 17)\n",
      "Validation set: (28140, 17)\n",
      "Training target distribution:\n",
      " Depression\n",
      "0    92106\n",
      "1    20454\n",
      "Name: count, dtype: int64\n",
      "Validation target distribution:\n",
      " Depression\n",
      "0    23027\n",
      "1     5113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Drop columns not useful for prediction\n",
    "df_clean = df.drop(columns=[\"id\", \"Name\"])\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_cols.remove('Depression')  # Target column\n",
    "\n",
    "# Fill missing values\n",
    "df_clean[categorical_cols] = df_clean[categorical_cols].fillna('Unknown')\n",
    "df_clean[numerical_cols] = df_clean[numerical_cols].fillna(df_clean[numerical_cols].median())\n",
    "\n",
    "# Save medians for test-time imputation\n",
    "medians = df_clean[numerical_cols].median()\n",
    "joblib.dump(medians, \"medians.pkl\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Save label encoders\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_clean[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Save column names for reuse\n",
    "joblib.dump(categorical_cols, \"categorical_cols.pkl\")\n",
    "joblib.dump(numerical_cols, \"numerical_cols.pkl\")\n",
    "\n",
    "# Split into features and target\n",
    "X = df_clean.drop(columns='Depression')\n",
    "y = df_clean['Depression']\n",
    "\n",
    "# Train-validation split (80-20), stratified to preserve class distribution\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Final shapes\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n",
    "print(\"Training target distribution:\\n\", y_train.value_counts())\n",
    "print(\"Validation target distribution:\\n\", y_val.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e057a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 472.0682, Val Loss: 0.1698, Val Accuracy: 0.9317\n",
      "Epoch 2/10, Loss: 315.4934, Val Loss: 0.1634, Val Accuracy: 0.9335\n",
      "Epoch 3/10, Loss: 304.1693, Val Loss: 0.1670, Val Accuracy: 0.9337\n",
      "Epoch 4/10, Loss: 300.0641, Val Loss: 0.1681, Val Accuracy: 0.9331\n",
      "Epoch 5/10, Loss: 296.6951, Val Loss: 0.1691, Val Accuracy: 0.9323\n",
      "Epoch 6/10, Loss: 294.9240, Val Loss: 0.1611, Val Accuracy: 0.9356\n",
      "Epoch 7/10, Loss: 293.0425, Val Loss: 0.1615, Val Accuracy: 0.9369\n",
      "Epoch 8/10, Loss: 291.4882, Val Loss: 0.1614, Val Accuracy: 0.9373\n",
      "Epoch 9/10, Loss: 292.6860, Val Loss: 0.1629, Val Accuracy: 0.9367\n",
      "Epoch 10/10, Loss: 292.0347, Val Loss: 0.1612, Val Accuracy: 0.9362\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert the NumPy data from preprocessing into PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the MLP architecture\n",
    "class DepressionMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DepressionMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = DepressionMLP(input_dim=X_train.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor).item()\n",
    "        val_preds = (val_outputs >= 0.5).float()\n",
    "        val_accuracy = (val_preds == y_val_tensor).float().mean().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e0d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of            id     Name  Gender   Age           City  \\\n",
       "0      140700   Shivam    Male  53.0  Visakhapatnam   \n",
       "1      140701    Sanya  Female  58.0        Kolkata   \n",
       "2      140702     Yash    Male  53.0         Jaipur   \n",
       "3      140703   Nalini  Female  23.0         Rajkot   \n",
       "4      140704  Shaurya    Male  47.0         Kalyan   \n",
       "...       ...      ...     ...   ...            ...   \n",
       "93795  234495     Zoya  Female  49.0         Jaipur   \n",
       "93796  234496    Shlok    Male  29.0      Ahmedabad   \n",
       "93797  234497    Rishi    Male  24.0  Visakhapatnam   \n",
       "93798  234498   Eshita  Female  23.0         Kalyan   \n",
       "93799  234499    Gauri  Female  43.0       Varanasi   \n",
       "\n",
       "      Working Professional or Student              Profession  \\\n",
       "0                Working Professional                   Judge   \n",
       "1                Working Professional  Educational Consultant   \n",
       "2                Working Professional                 Teacher   \n",
       "3                             Student                     NaN   \n",
       "4                Working Professional                 Teacher   \n",
       "...                               ...                     ...   \n",
       "93795            Working Professional                   Pilot   \n",
       "93796            Working Professional                   Pilot   \n",
       "93797                         Student                     NaN   \n",
       "93798            Working Professional       Marketing Manager   \n",
       "93799            Working Professional  Educational Consultant   \n",
       "\n",
       "       Academic Pressure  Work Pressure  CGPA  Study Satisfaction  \\\n",
       "0                    NaN            2.0   NaN                 NaN   \n",
       "1                    NaN            2.0   NaN                 NaN   \n",
       "2                    NaN            4.0   NaN                 NaN   \n",
       "3                    5.0            NaN  6.84                 1.0   \n",
       "4                    NaN            5.0   NaN                 NaN   \n",
       "...                  ...            ...   ...                 ...   \n",
       "93795                NaN            3.0   NaN                 NaN   \n",
       "93796                NaN            5.0   NaN                 NaN   \n",
       "93797                1.0            NaN  7.51                 4.0   \n",
       "93798                NaN            4.0   NaN                 NaN   \n",
       "93799                NaN            5.0   NaN                 NaN   \n",
       "\n",
       "       Job Satisfaction     Sleep Duration Dietary Habits  Degree  \\\n",
       "0                   5.0  Less than 5 hours       Moderate     LLB   \n",
       "1                   4.0  Less than 5 hours       Moderate    B.Ed   \n",
       "2                   1.0          7-8 hours       Moderate  B.Arch   \n",
       "3                   NaN  More than 8 hours       Moderate     BSc   \n",
       "4                   5.0          7-8 hours       Moderate     BCA   \n",
       "...                 ...                ...            ...     ...   \n",
       "93795               5.0  Less than 5 hours       Moderate     BSc   \n",
       "93796               1.0          7-8 hours       Moderate      BE   \n",
       "93797               NaN          7-8 hours       Moderate  B.Tech   \n",
       "93798               2.0          5-6 hours        Healthy      BA   \n",
       "93799               2.0  More than 8 hours        Healthy    B.Ed   \n",
       "\n",
       "      Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
       "0                                        No               9.0   \n",
       "1                                        No               6.0   \n",
       "2                                       Yes              12.0   \n",
       "3                                       Yes              10.0   \n",
       "4                                       Yes               3.0   \n",
       "...                                     ...               ...   \n",
       "93795                                   Yes               2.0   \n",
       "93796                                   Yes              11.0   \n",
       "93797                                    No               7.0   \n",
       "93798                                   Yes               7.0   \n",
       "93799                                    No              11.0   \n",
       "\n",
       "       Financial Stress Family History of Mental Illness  \n",
       "0                   3.0                              Yes  \n",
       "1                   4.0                               No  \n",
       "2                   4.0                               No  \n",
       "3                   4.0                               No  \n",
       "4                   4.0                               No  \n",
       "...                 ...                              ...  \n",
       "93795               2.0                              Yes  \n",
       "93796               3.0                              Yes  \n",
       "93797               1.0                               No  \n",
       "93798               5.0                              Yes  \n",
       "93799               2.0                               No  \n",
       "\n",
       "[93800 rows x 19 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a75a029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Accuracy: 0.9308 | Precision: 0.8599 | Recall: 0.7397 | F1 Score: 0.7953\n",
      "Epoch 2/10 | Accuracy: 0.9333 | Precision: 0.8208 | Recall: 0.8099 | F1 Score: 0.8153\n",
      "Epoch 3/10 | Accuracy: 0.9348 | Precision: 0.8557 | Recall: 0.7710 | F1 Score: 0.8111\n",
      "Epoch 4/10 | Accuracy: 0.9353 | Precision: 0.8508 | Recall: 0.7810 | F1 Score: 0.8144\n",
      "Epoch 5/10 | Accuracy: 0.9357 | Precision: 0.8359 | Recall: 0.8040 | F1 Score: 0.8197\n",
      "Epoch 6/10 | Accuracy: 0.9353 | Precision: 0.8136 | Recall: 0.8349 | F1 Score: 0.8241\n",
      "Epoch 7/10 | Accuracy: 0.9361 | Precision: 0.8288 | Recall: 0.8171 | F1 Score: 0.8229\n",
      "Epoch 8/10 | Accuracy: 0.9330 | Precision: 0.8829 | Recall: 0.7281 | F1 Score: 0.7981\n",
      "Epoch 9/10 | Accuracy: 0.9366 | Precision: 0.8396 | Recall: 0.8046 | F1 Score: 0.8217\n",
      "Epoch 10/10 | Accuracy: 0.9359 | Precision: 0.8580 | Recall: 0.7753 | F1 Score: 0.8145\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df.drop(columns=[\"id\", \"Name\"])\n",
    "\n",
    "# Preprocessing\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_cols.remove('Depression')\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].fillna('Unknown')\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Split data\n",
    "X = df.drop(columns='Depression')\n",
    "y = df['Depression']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=64)\n",
    "\n",
    "# MLP Model\n",
    "class DepressionMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DepressionMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Training and Evaluation Pipeline\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_preds = (val_outputs >= 0.5).float()\n",
    "\n",
    "            acc = accuracy_score(y_val_tensor, val_preds)\n",
    "            prec = precision_score(y_val_tensor, val_preds)\n",
    "            rec = recall_score(y_val_tensor, val_preds)\n",
    "            f1 = f1_score(y_val_tensor, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Accuracy: {acc:.4f} | Precision: {prec:.4f} \"\n",
    "              f\"| Recall: {rec:.4f} | F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Initialize and train\n",
    "input_dim = X_train.shape[1]\n",
    "model = DepressionMLP(input_dim)\n",
    "train_model(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a7ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 1.9177, Val Loss: 1.2790, Val Acc: 0.2819\n",
      "Epoch 2/50, Train Loss: 1.3894, Val Loss: 0.8427, Val Acc: 0.4483\n",
      "Epoch 3/50, Train Loss: 0.9820, Val Loss: 0.5810, Val Acc: 0.7140\n",
      "Epoch 4/50, Train Loss: 0.7196, Val Loss: 0.4918, Val Acc: 0.8183\n",
      "Epoch 5/50, Train Loss: 0.5957, Val Loss: 0.5079, Val Acc: 0.8183\n",
      "Epoch 6/50, Train Loss: 0.5696, Val Loss: 0.5610, Val Acc: 0.8183\n",
      "Epoch 7/50, Train Loss: 0.5914, Val Loss: 0.6163, Val Acc: 0.8183\n",
      "Epoch 8/50, Train Loss: 0.6280, Val Loss: 0.6608, Val Acc: 0.8183\n",
      "Epoch 9/50, Train Loss: 0.6628, Val Loss: 0.6910, Val Acc: 0.8183\n",
      "Epoch 10/50, Train Loss: 0.6878, Val Loss: 0.7071, Val Acc: 0.8183\n",
      "Epoch 11/50, Train Loss: 0.7020, Val Loss: 0.7108, Val Acc: 0.8183\n",
      "Epoch 12/50, Train Loss: 0.7064, Val Loss: 0.7039, Val Acc: 0.8183\n",
      "Epoch 13/50, Train Loss: 0.7026, Val Loss: 0.6885, Val Acc: 0.8183\n",
      "Epoch 14/50, Train Loss: 0.6877, Val Loss: 0.6665, Val Acc: 0.8183\n",
      "Epoch 15/50, Train Loss: 0.6695, Val Loss: 0.6400, Val Acc: 0.8183\n",
      "Epoch 16/50, Train Loss: 0.6475, Val Loss: 0.6107, Val Acc: 0.8183\n",
      "Epoch 17/50, Train Loss: 0.6192, Val Loss: 0.5804, Val Acc: 0.8183\n",
      "Epoch 18/50, Train Loss: 0.5953, Val Loss: 0.5507, Val Acc: 0.8183\n",
      "Epoch 19/50, Train Loss: 0.5708, Val Loss: 0.5230, Val Acc: 0.8183\n",
      "Epoch 20/50, Train Loss: 0.5485, Val Loss: 0.4985, Val Acc: 0.8183\n",
      "Epoch 21/50, Train Loss: 0.5251, Val Loss: 0.4783, Val Acc: 0.8183\n",
      "Epoch 22/50, Train Loss: 0.5102, Val Loss: 0.4630, Val Acc: 0.8183\n",
      "Epoch 23/50, Train Loss: 0.5006, Val Loss: 0.4526, Val Acc: 0.8183\n",
      "Epoch 24/50, Train Loss: 0.4951, Val Loss: 0.4468, Val Acc: 0.8183\n",
      "Epoch 25/50, Train Loss: 0.4946, Val Loss: 0.4448, Val Acc: 0.8183\n",
      "Epoch 26/50, Train Loss: 0.4982, Val Loss: 0.4453, Val Acc: 0.8183\n",
      "Epoch 27/50, Train Loss: 0.5022, Val Loss: 0.4470, Val Acc: 0.8185\n",
      "Epoch 28/50, Train Loss: 0.5090, Val Loss: 0.4487, Val Acc: 0.8192\n",
      "Epoch 29/50, Train Loss: 0.5089, Val Loss: 0.4495, Val Acc: 0.8190\n",
      "Epoch 30/50, Train Loss: 0.5118, Val Loss: 0.4491, Val Acc: 0.8188\n",
      "Epoch 31/50, Train Loss: 0.5084, Val Loss: 0.4476, Val Acc: 0.8190\n",
      "Epoch 32/50, Train Loss: 0.5061, Val Loss: 0.4454, Val Acc: 0.8192\n",
      "Epoch 33/50, Train Loss: 0.4996, Val Loss: 0.4429, Val Acc: 0.8194\n",
      "Epoch 34/50, Train Loss: 0.4919, Val Loss: 0.4409, Val Acc: 0.8190\n",
      "Epoch 35/50, Train Loss: 0.4865, Val Loss: 0.4395, Val Acc: 0.8184\n",
      "Epoch 36/50, Train Loss: 0.4822, Val Loss: 0.4391, Val Acc: 0.8183\n",
      "Epoch 37/50, Train Loss: 0.4777, Val Loss: 0.4397, Val Acc: 0.8183\n",
      "Epoch 38/50, Train Loss: 0.4742, Val Loss: 0.4410, Val Acc: 0.8183\n",
      "Epoch 39/50, Train Loss: 0.4716, Val Loss: 0.4430, Val Acc: 0.8183\n",
      "Epoch 40/50, Train Loss: 0.4703, Val Loss: 0.4452, Val Acc: 0.8183\n",
      "Epoch 41/50, Train Loss: 0.4687, Val Loss: 0.4473, Val Acc: 0.8183\n",
      "Epoch 42/50, Train Loss: 0.4697, Val Loss: 0.4490, Val Acc: 0.8183\n",
      "Epoch 43/50, Train Loss: 0.4700, Val Loss: 0.4502, Val Acc: 0.8183\n",
      "Epoch 44/50, Train Loss: 0.4705, Val Loss: 0.4506, Val Acc: 0.8183\n",
      "Epoch 45/50, Train Loss: 0.4701, Val Loss: 0.4502, Val Acc: 0.8183\n",
      "Epoch 46/50, Train Loss: 0.4686, Val Loss: 0.4489, Val Acc: 0.8183\n",
      "Epoch 47/50, Train Loss: 0.4662, Val Loss: 0.4470, Val Acc: 0.8183\n",
      "Epoch 48/50, Train Loss: 0.4650, Val Loss: 0.4445, Val Acc: 0.8183\n",
      "Epoch 49/50, Train Loss: 0.4630, Val Loss: 0.4416, Val Acc: 0.8183\n",
      "Epoch 50/50, Train Loss: 0.4606, Val Loss: 0.4385, Val Acc: 0.8183\n",
      "Model and preprocessing artifacts saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_clean = df.drop(columns=[\"id\", \"Name\"])\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_cols.remove('Depression')  # Target column\n",
    "\n",
    "# Handle missing values\n",
    "df_clean[categorical_cols] = df_clean[categorical_cols].fillna('Unknown')\n",
    "df_clean[numerical_cols] = df_clean[numerical_cols].fillna(df_clean[numerical_cols].median())\n",
    "\n",
    "# Save medians\n",
    "medians = df_clean[numerical_cols].median()\n",
    "joblib.dump(medians, \"medians.pkl\")\n",
    "\n",
    "# Label encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_clean[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Save column names\n",
    "joblib.dump(categorical_cols, \"categorical_cols.pkl\")\n",
    "joblib.dump(numerical_cols, \"numerical_cols.pkl\")\n",
    "\n",
    "# Features and target\n",
    "X = df_clean.drop(columns='Depression')\n",
    "y = df_clean['Depression']\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define a simple MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()  # Binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = MLP(input_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_val_tensor)\n",
    "        val_loss = criterion(val_preds, y_val_tensor)\n",
    "        val_acc = ((val_preds >= 0.5).float() == y_val_tensor).float().mean()\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc.item():.4f}\")\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "print(\"Model and preprocessing artifacts saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d019d049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the same model class used during training\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load categorical and numerical column lists\n",
    "categorical_cols = joblib.load(\"categorical_cols.pkl\")\n",
    "numerical_cols = joblib.load(\"numerical_cols.pkl\")\n",
    "input_dim = len(categorical_cols) + len(numerical_cols)\n",
    "\n",
    "# Load model weights\n",
    "model = MLP(input_dim)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76309e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions complete. Sample output:\n",
      "   Predicted_Depression\n",
      "0                     0\n",
      "1                     0\n",
      "2                     0\n",
      "3                     0\n",
      "4                     0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load preprocessing artifacts from training\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "categorical_cols = joblib.load(\"categorical_cols.pkl\")\n",
    "numerical_cols = joblib.load(\"numerical_cols.pkl\")\n",
    "medians = joblib.load(\"medians.pkl\")\n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "test_df_clean = test_df.drop(columns=[\"id\", \"Name\"])\n",
    "\n",
    "# Handle missing values\n",
    "test_df_clean[categorical_cols] = test_df_clean[categorical_cols].fillna('Unknown')\n",
    "test_df_clean[numerical_cols] = test_df_clean[numerical_cols].fillna(medians)\n",
    "\n",
    "# Replace unseen categories and encode\n",
    "for col in categorical_cols:\n",
    "    le = label_encoders[col]\n",
    "    if 'Unknown' not in le.classes_:\n",
    "        le.classes_ = np.append(le.classes_, 'Unknown')\n",
    "    known_classes = set(le.classes_)\n",
    "    test_df_clean[col] = test_df_clean[col].apply(lambda x: x if x in known_classes else 'Unknown')\n",
    "    test_df_clean[col] = le.transform(test_df_clean[col])\n",
    "\n",
    "# Normalize numerical columns\n",
    "test_df_clean[numerical_cols] = scaler.transform(test_df_clean[numerical_cols])\n",
    "\n",
    "# Convert to tensor for model input\n",
    "X_test_tensor = torch.tensor(test_df_clean.values, dtype=torch.float32)\n",
    "\n",
    "# Predict using the trained PyTorch model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_preds = (test_outputs >= 0.5).int().numpy().flatten()\n",
    "\n",
    "# Add predictions to the original test set\n",
    "test_results = test_df.copy()\n",
    "test_results['Predicted_Depression'] = test_preds\n",
    "\n",
    "# Save to CSV (optional)\n",
    "test_results.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "# Print sample results\n",
    "print(\"Predictions complete. Sample output:\")\n",
    "print(test_results[['Predicted_Depression']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
